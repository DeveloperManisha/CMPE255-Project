{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/driver_imgs_list.csv\n"
     ]
    }
   ],
   "source": [
    "path='../data/'\n",
    "list_path= path+'driver_imgs_list.csv'\n",
    "print(list_path)\n",
    "image_dataset = pd.read_csv(list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image_dataset['img']\n",
    "y=image_dataset['classname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,test_size = 0.20,train_size =0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17939"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)\n",
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "for i in range(0,x_train.size):\n",
    "    cr_path ='../train/' + y_train.iloc[i] + '/'\n",
    "    if (not os.path.exists(cr_path)):\n",
    "        os.makedirs(cr_path)\n",
    "    shutil.copyfile('../data/imgs/train/' + y_train.iloc[i] + '/' + x_train.iloc[i], '../train/' + y_train.iloc[i] + '/' + x_train.iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,x_val.size):\n",
    "    cr_path ='../validation/' + y_val.iloc[i] + '/'\n",
    "    if (not os.path.exists(cr_path)):\n",
    "        os.makedirs(cr_path)\n",
    "    shutil.copyfile('../data/imgs/train/' + y_val.iloc[i] + '/' + x_val.iloc[i], '../validation/' + y_val.iloc[i] + '/' + x_val.iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishashivshette/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_data_generator=ImageDataGenerator(\n",
    "                        rescale=1./255,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17939 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = image_data_generator.flow_from_directory(\n",
    "        '../train',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4485 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = test_datagenerator.flow_from_directory(\n",
    "        '../validation',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 1.3529 - acc: 0.5275 - val_loss: 0.7079 - val_acc: 0.7908\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 548s 274ms/step - loss: 0.8334 - acc: 0.7190 - val_loss: 0.3870 - val_acc: 0.8985\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 499s 249ms/step - loss: 0.5986 - acc: 0.8018 - val_loss: 0.2718 - val_acc: 0.9263\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 517s 259ms/step - loss: 0.4686 - acc: 0.8489 - val_loss: 0.2198 - val_acc: 0.9420\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 500s 250ms/step - loss: 0.3908 - acc: 0.8760 - val_loss: 0.1781 - val_acc: 0.9565\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 482s 241ms/step - loss: 0.3389 - acc: 0.8940 - val_loss: 0.1644 - val_acc: 0.9553\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 458s 229ms/step - loss: 0.3034 - acc: 0.9047 - val_loss: 0.1394 - val_acc: 0.9636\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 429s 214ms/step - loss: 0.2805 - acc: 0.9134 - val_loss: 0.1227 - val_acc: 0.9680\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 440s 220ms/step - loss: 0.2610 - acc: 0.9183 - val_loss: 0.1109 - val_acc: 0.9717\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 445s 223ms/step - loss: 0.2475 - acc: 0.9249 - val_loss: 0.1064 - val_acc: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a285f6da0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_array = [100,200,300,1000,2000]\n",
    "epochs_array = [10,20,30,40,50]\n",
    "validation_steps_array=[100,200,300,400,800]\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch_array[4],\n",
    "        epochs=epochs_array[0],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps_array[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names\n",
    "result=model.evaluate_generator(generator=validation_generator,steps=4485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss is 0.106529 accuracy is 0.973419 \n"
     ]
    }
   ],
   "source": [
    "print(\"Model loss is %f accuracy is %f \"%(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_using_keras.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
